#+Title: JOM299
#+Author: Basile Simon
#+Email: @basilesimon

#+OPTIONS: toc:nil num:nil
#+OPTIONS: reveal_width:1200
#+OPTIONS: reveal_height:800
#+REVEAL_MARGIN: 0.1
#+REVEAL_MIN_SCALE: 0.5
#+REVEAL_MAX_SCALE: 2.5
#+OPTIONS: reveal_center:nil 
#+OPTIONS: reveal_rolling_links:t reveal_keyboard:t reveal_overview:t 
#+OPTIONS: org-html-indent:nil
#+REVEAL_TRANS: linear
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Title">
#+REVEAL_ROOT: http://cdn.jsdelivr.net/reveal.js/3.0.0/
#+REVEAL_EXTRA_CSS: ../presentation/mozilla-devrel-light.css
#+REVEAL_PLUGINS: (highlight)
#+REVEAL_HLEVEL: 2


* TODO teaching plan
** Week 1 - The basics

  The mysterious creature that is the DOM, what a webpage actually is, and using the DevTools.  

  We'll have a look at the very basics of working with the web. Having done the pre-course work (Codecademy Javascript tutorial), we hopefully won't lost much time. No set-up involved, j5ust simple practical exercises in a web browser

*** Session 1: practical exercises
*** Session 2: more exercises

** Week 2 - Working with Python and data

  A foundation session in which we'll talk about some basics such as file formats and, er, where do you write code in the first place. We'll rattle through some online resources and communities where you can get help if you're stuck with a problem.
  During the second session we'll see the basics of the Python programming language.

*** Session 1: file formats, writing code, exploratory data analysis
*** Session 2: intro to Python

** Week 3 - Concrete scraping examples in Python

  A heavy session made up of short examples we'll study and extract data from.

*** Session 1: simple scraping
*** Session 2: more complex scraping, saving data

** Week 4 - R in the newsroom

  Armed with our new best friend RStudio, we'll introduce the R programming language and explore the fantastic `tidyverse`, as well as plotting our first charts.

*** Session 1: the tidyverse
*** Session 2: ggplot

** Week 5 - Concrete R exercises

  We'll touch on statistics concepts and keep proving how great R is at prototyping and wrangling data and charts.

*** Session 1: data cleaning exercises
*** Session 2: enough stats to keep you out of trouble

** Week 6 - More R
   
  ???

** Week 7 - Into Javascript charts world

  An overview of what is data viz and how central D3.js is to the discipline. We'll however pivot quickly towards Highcharts.js for its simplicity. As for the R sessions, we'll work through basic plotting then more complex examples.

*** Session 1: overview of the discipline, Highcharts
*** Session 2: Highcharts + misc explorations

** Weeks 8, 9, 10 - Project work

  We will go round the room and take questions from students about their final project. Come prepared with actual problems, be happy to work collaboratively and to make progress in class while we tackle challenges collectively, on the big screen. These sessions are usually the time when "ha-ha" moments happen.


* moodle
  :LOGBOOK:
  CLOCK: [2018-01-18 Thu 11:32]--[2018-01-18 Thu 11:55] =>  0:23
  :END:
** DONE week-by-week outline
   CLOSED: [2018-01-18 Thu 11:55]

* 1.1: The basics
  :LOGBOOK:
  CLOCK: [2018-01-23 Tue 22:45]--[2018-01-23 Tue 23:04] =>  0:19
  CLOCK: [2018-01-23 Tue 17:51]--[2018-01-23 Tue 18:29] =>  0:38
  CLOCK: [2018-01-18 Thu 20:31]--[2018-01-18 Thu 20:56] =>  0:25
  CLOCK: [2017-12-27 Wed 16:00]--[2017-12-27 Wed 16:39] =>  0:39
  :END:
** module information
   Module code: JOM299
   Title: Advanced Data and Coding

   - Module and assessment outline
   - The self-learner attitude
   - Useful resources
   - Intro to the DevTools, the DOM, and debugging your things
** topics covered in this module
   - Introduction to programming and the web with Javascript
   - Basic web scraping with Python
   - Exploratory analysis and day-to-day work with R
   - Putting charts on the web
** module outline and goals according to the spec
   - Develop a *complex skillset*
   - Gain an *understanding of data* and of modern digital journalism
   - Develop a *problem-solving philosophy*
   - Acquire *self-direction in learning*

** and I add to this:
 *Have a crucial advantage over others in the industry*

** assessment: mark split between...
*** 25% presentation and brief
   Will take place on *week 5*

   i.e.
- Wed 21 
- or Fri 23
*** 75% final project
   mid-April?
** cherry on top: build in JS week 3
    #+BEGIN_QUOTE
    Build a simple interactive thing, in Javascript. This can be a series of buttons on which to click to change a displayed information, for example. The action triggered will involve a function. Example: display "1". Upon clicking this button, a function adds 2 and displays "3". Ask the user for a number to add, display the result of 3+n.
    #+END_QUOTE

   We'll talk about this project in class

** assessment two: final project
    
   #+BEGIN_QUOTE
   Your project should identify and solve a journalistic problem, using data and coding work. Typically this will focus on a story -- either a complete story or an interactive feature forming part of a story. It could also be something for use in a newsroom (eg a tool helpful to journalists). 
   #+END_QUOTE

   that's from the course specs

** more about the final project
   Your project must be relevant to journalism (see above), operate at a functional level (at least as a working prototype), and involve all of the following:

   - data techniques, involving scraping, cleaning, analysis and/or presentation, as needed/appropriate to your project
   - adding value through user interactivity
   - use and modification of html, CSS, Javascript, Python, R, d3 
   - and/or other code (not simply plug-and-play elements)
   - use of free and/or low-cost tools
   - problem-solving.

   (that's also from the spec)

** the self-learner attitude - what is that?
   I want you to engage in the community of data-journalists, news hackers and tinkerers

   - [[https://news.ycombinator.com/item?id=13148319][Tips for self-learning (Hacker News)]]
   - [[https://www.reddit.com/r/dataisbeautiful/][/r/dataisbeautiful community]]
   - [[http://newsnerdery.org/][News Nerdery (Slack)]]
   - RSS feeds, Twitter...

** without further ado...
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/26uf6o80xhd6MKGIw/giphy.gif
    :reveal_background_trans: slide
    :END:

** what is the DOM?
   [http://domenlightenment.com/#1.1]

   #+BEGIN_QUOTE
   The DOM is a hierarchy/tree of Javascript node objects
   #+END_QUOTE

   - It looks like the HTML you wrote
   - It actually is the programming interface around it

** programming interface?
   #+BEGIN_SRC html
   <body>
     <article>
       <h1>This is a simple title</h1>

       <h1 id="special">This is another title... 
         <em>with a twist!</em>
       </h1>
     </article>
   </body>
   #+END_SRC

   Let's have a look: [[http://codepen.io/basilesimon/pen/PWNXEK][Codepen]]

** wait, console.log()?
   #+ATTR_REVEAL: :frag (appear)
   The Dev Tools: the Swiss army knife of web work

   What you can do with Dev Tools:
   - Edit the DOM directly
   - Change styles of any page
   - See Javascript code and errors
   - See and edit any file loaded by the page

** let's access the Dev Tools
   On Chrome and Firefox
   - `Ctrl` + `Shift` + `I` 
   - or `Cmd` + `Opt` + `I` on a Mac

** do things with the Dev Tools
   Inspect and edit pages and style: 
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/][exercise one]]
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/edit-styles][exercise two]]
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/edit-dom][exercise three]]

** editing HTML with the Dev Tools
   Example: make Donald Trump say anything with the Dev Tools!

** hiding things with the Dev Tools
   Example: hide something on the [[https://www.google.co.uk/][Google homepage]]

** homework
-  [[http://codepen.io/basilesimon/pen/BQgwxG?editors=1100#0][Fix these images]]
-  [[http://codepen.io/basilesimon/pen/PWjJwg][Hide DOM elements]]
-  [[http://discover-devtools.codeschool.com/chapters/1?locale=en][Play with the dom]]

* 1.2: More exercises
  :LOGBOOK:
  CLOCK: [2018-01-25 Thu 20:21]--[2018-01-25 Thu 23:51] =>  3:30
  CLOCK: [2018-01-18 Thu 21:24]--[2018-01-18 Thu 21:32] =>  0:08
  CLOCK: [2018-01-15 Mon 20:54]--[2018-01-15 Mon 21:29] =>  0:35
  CLOCK: [2018-01-15 Mon 20:30]--[2018-01-15 Mon 20:54] =>  0:24
  CLOCK: [2017-12-27 Wed 16:39]--[2017-12-27 Wed 16:54] =>  0:15
  :END:
** useful links
   - [[https://www.thetimes.co.uk/article/digital-news-work-experience-qmg8f9585][The Times and Sunday Times work experience]]
   [[https://www.theguardian.com/gnmeducationcentre/journalism-work-experience-opportunities-young-people][- The Guardian work experience]]
** final projects
   [[https://ellawilksharper.github.io/a-day-in-the-life-of-mps/]]
   [[https://nellmooney.github.io/thecasting/]]
   [[https://alexandrama.github.io/trump-frequent-mentions/]]
** recap from last session
   #+ATTR_REVEAL: :frag (appear)
   - what is the DOM: a tree-like structure and a programming interface around it
   - HTML structures
   - Basics of Javascript: our way to interact with the DOM (among others)
   
   #+ATTR_REVEAL: :frag (appear)
   Let's have a look: [[http://codepen.io/basilesimon/pen/PWNXEK][Codepen]]

** picking up the homework: exercise 1

-  [[http://codepen.io/basilesimon/pen/BQgwxG?editors=1100#0][Fix these images]]

*** Image one: spot the typo
    #+BEGIN_SRC html
    <img src="http://some-url/image.jpg" />
    #+END_SRC

    #+BEGIN_SRC html
    <img scr="http://some-url/image.jpg" />
    #+END_SRC

    we want `src=...`, not `scr=...` - pay attention to typos!
*** Image two
    missing closing bracket `>`

    #+BEGIN_SRC
    // bad
    <img src="http://some-url/image.jpg"
    #+END_SRC

    #+BEGIN_SRC html
    // good
    <img src="http://some-url/image.jpg" />
    #+END_SRC
*** Image three: all good
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/d31x1fB3jEBvQ7E4/giphy.gif
    :reveal_background_trans: slide
    :END:

** picking up the homework: exercise 2
*** "how to hide div css" google search

    [[https://www.sitepoint.com/five-ways-to-hide-elements-in-css/][google search]]

*** solution
   #+BEGIN_SRC css
   #toHide { visibility: hidden; }
   #+END_SRC

   or

   #+BEGIN_SRC css
   #toHide { display: none; }
   #+END_SRC

** codecademy homework
** what's a variable?

   A variable is a store, in which you can put different data:
   #+ATTR_REVEAL: :frag (appear)
   - your age (a number)
   - your name (a string)
   - the result of a logical operation (true/false)
   
   #+BEGIN_SRC js
   var myAge = 26;
   var myName = "Basile";
   var doITeachAtCity = true;
   #+END_SRC

** what are the different data types?
   #+ATTR_REVEAL: :frag (appear)
   - *string*: takes quotation marks around it. example: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var name = "basile"; var age = "30";
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *number*: no quotation marks. example: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var number = 10; var budget = 1245.5;
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *boolean*: logical operators: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var basileIsHere = true; var basileIsShaved = false;
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *array/list* (more later)
   - *object* (more later)
   - *null/undefined*
** data types: lists/arrays
   #+BEGIN_SRC js
   var thisIsAList = [1,2,3,'basile'];
   #+END_SRC

   contained between brackets, they store items in them. we can access these items like so:

   #+BEGIN_SRC js
   thisIsAList[0] // 1
   thisIsAList[3] // 'basile'
   #+END_SRC

   Note: lists are said 'zero-padded'
** data types: objects
   #+BEGIN_SRC js
   var thisIsAnObject = { name: 'basile', age: 26 };
   #+END_SRC

   kind of like lists, but object items can be accessed by their key, like so:

   #+BEGIN_SRC js
   console.log(thisIsAnObject.name); // 'basile'
   console.log(thisIsAnObject.age); // 26
   #+END_SRC

** what we use data types for

   different data have different use cases.

   #+ATTR_REVEAL: :frag (appear)
   - text is obviously a **string**
   - if you try to plot numbers on a chart or do maths, you better use **numbers**, not strings
   - **booleans** will be useful to do logical checks, e.g. "show me all MPs whose age is over 60"

** what we use data types for (repeat)

   different data have different use cases.

   #+ATTR_REVEAL: :frag (appear)
   - **lists** can be *iterated over*, i.e. "for each element in this list, do that"
   
     think of an Excel column with a formula that you drag down to apply it to all cells
   #+ATTR_REVEAL: :frag (appear)
   - **objects** are excellent *data stores* and more rich than so-called *flat* lists

** the for loop
   very useful pattern: `for` iterates over list items.

   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var myList = [1,2,10,37];

   myList.forEach(function(element) {
     console.log(element);
     console.log(element + 1);
   }
   // 1, 2, 10, 37
   // 2, 3, 11, 38
   #+END_SRC

   #+ATTR_REVEAL: :frag (appear)
   - for each item  in my array,
   - log the said item plus one.

** the function

   functions are used to break down your code into separate, simple tasks

   #+BEGIN_SRC js
   function sayMyName(name) {
     console.log('HELLO' + name);
   };
   sayMyName('basile') // HELLO basile
   #+END_SRC

** the function (repeat)
   iterating over an array with a function

   #+BEGIN_SRC js
   // define a function like so
   function applyFunction(takesAVariableIn) {
     console.log(takesAVariableIn + ' is great'!
   }

   // define a variable, an array/list in this case
   var thisIsAVariable = ['basile', 'city uni'];

   // for each element of the array, run the function
   thisIsAVariable.forEach(function(element) {
     applyFunction(element);
   })
   #+END_SRC

** writing code: online code editors
   
   Purpose: no need to put files on your computer
   Just write code and go

   Tip: you might need the devtools to see your javascript!
   
   - JSBin
   - Codepen

** let's have a look 
   [[https://codepen.io/basilesimon/pen/GybzoE?editors=1010#0]]
   [[https://codepen.io/basilesimon/pen/XVLOXv?editors=1010]]
** online code editor demo: week 3 project
** examples
   https://codepen.io/basilesimon/pen/xpmGmN?editors=1010

** let's practice
   
   an addition I made yesterday to my dataviz catalogue for the Times:

   [[https://github.com/times/dataviz-catalogue/pull/28]]

   practice: https://codepen.io/basilesimon/pen/MrMNXX

   #+ATTR_REVEAL: :frag (appear)
   [[https://codepen.io/basilesimon/pen/ppXGBz]]

** homework
* 2.1: File formats, writing code
  :LOGBOOK:
  CLOCK: [2018-01-29 Mon 22:52]--[2018-01-30 Tue 00:25] =>  1:33
  CLOCK: [2018-01-29 Mon 18:45]--[2018-01-29 Mon 19:30] =>  0:45
  CLOCK: [2018-01-27 Sat 16:42]--[2018-01-27 Sat 19:42] =>  3:00
  CLOCK: [2018-01-18 Thu 12:07]--[2018-01-18 Thu 13:33] =>  1:26
  :END:

** file formats

   as for scripts (instructions) and web pages, we sometimes need to store data in files ("datasets").

   that's what you'd get from the ONS, data.gov.uk, an API, etc.

   there are different file formats for different purposes.

** file formats: CSV

   standing for Comma-Separated Values, CSV will be of much use to us when it comes to data.

   #+BEGIN_SRC
   myfile.csv
   #+END_SRC

   think of a spreadsheet without any formatting: 
   * every line in the file is a row,
   * every comma-separated value is a cell

*** CSV structure

   #+BEGIN_SRC
   name, occupation, height
   basile, journalist, 187
   donald, politician, 188
   #+END_SRC

** file formats: JSON

   standing for JavaScript Object Notation, JSON is almost universally used on the web.

   #+BEGIN_SRC
   myfile.json
   #+END_SRC

   structure in objects (`var anObject = {};`) separated by commas.
   made up of `key: value` pairs.

*** JSON structure

   #+BEGIN_SRC
   var json = {
     "name": "Basile Simon",
     "occupation": "journalist",
     "friends": [ "pierre", "donald", "theresa"]
   }
   #+END_SRC

   #+BEGIN_SRC
   json.name => "Basile Simon"
   json.friends[0]` => "pierre"
   #+END_SRC

   https://codepen.io/basilesimon/pen/MrZWZg?editors=1010#

** JSON and CSV in this course

   we're likely to store data when scraping, cleaning, etc. in CSV format.
   we'll probably use, or "parse" CSV data into JSON for the web.

   d3.js has a CSV parser: from the CSV above

   #+BEGIN_SRC
   name, occupation, height
   basile, journalist, 187
   donald, politician, 188
   #+END_SRC

   we parse it as JSON, so we can run `data.name` and get "basile" back

** file formats: Excel, databases

   Excel/ Google Spreadsheets are **visual representations** or CSV data

   Databases come with, as the DOM does, their programming interface and language (eg SQL)

** a word about Python
** Python
   
    Python is a programming language created in 1991.

    It is the most taught programming language around the world.

*** Why Python?

    Newsroom use: https://www.poynter.org/news/introduction-newsroom-programming-technologies

    Python is very easy to read and to use - and many newsrooms use it.

    **If you can write Python, you can write anything.**
   
** What Python looks like

    **Javascript**
    #+BEGIN_SRC js
    var foo = 'bar';
    function myFunction(parameter) {
      console.log(parameter);
    };
    #+END_SRC

    **Python**
    #+BEGIN_SRC python
    foo = 'bar'
    def myFunction(parameter):
        print(parameter)
    #+END_SRC

** running your pythons: the notebook
    
    Python also comes with a set of utilities bundled in a GUI: [[http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb][the Jupyter Notebook]]

    We can run Python notebooks from the university computers.

    [[./images/jupyter.png]]

** data wrangling in Python
*** white house visitors
*** school earnings
** links
   
   [[https://plot.ly/python/ipython-notebook-tutorial/][A good notebook tutorial]]
   [[https://plot.ly/python/getting-started/][Plots in Python with Plotly (easy)]]
   [[http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.1/cookbook/Chapter%205%20-%20Combining%20dataframes%20and%20scraping%20Canadian%20weather%20data.ipynb][An excellent notebook with scraping and plotting]]
   [[https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/][Advanced data science methods]]

* 2.2: An intro to Python
  :LOGBOOK:
  CLOCK: [2018-02-01 Thu 23:59]--[2018-02-02 Fri 01:10] =>  1:11
  CLOCK: [2018-01-30 Tue 19:12]--[2018-01-30 Tue 23:12] =>  4:00
  CLOCK: [2018-01-18 Thu 22:12]--[2018-01-18 Thu 23:12] =>  1:00
  :END:
** final project inspiration
*** matteo

    [[https://matteofgmoschella.github.io/theageofthecyclists/#myPage]]

*** james

    [[https://jsomper.github.io/prisondata/]]

** final project don'ts
*** james

    [[https://jsomper.github.io/Antisemitism-project/]]

    it, er... didn't work. like, at all.

    lesson: submit something that works!

*** ayushman

    [[https://ayushman07.github.io/Final-Project/]]

    that's a photo essay without any interactive component to it.

    lesson: there is "data" in the module name. read the spec and make sure you tick the boxes.

** week 5 presentations
*** Reminder

    #+BEGIN_QUOTE 
    Pick one journalism piece/tool that illustrates a format or technique. Produce a presentation and report on the piece, how it's built, and the landscape of that format/technique in online journalism today.
    #+END_QUOTE

*** Example topics

    Some examples (please don't use these - come up with one of your own!):

    [[https://www.nytimes.com/interactive/2017/01/15/us/politics/you-draw-obama-legacy.html]]
    Storytelling interactivity

    [[https://www.buzzfeed.com/heidiblake/the-tennis-racket]]
    Algorithmic journalism, computer-assisted journalism

    [[https://www.theguardian.com/world/interactive/2013/nov/01/snowden-nsa-files-surveillance-revelations-decoded]]
    All-rounder

*** More example topics

    [[https://panamapapers.icij.org/]]
    [[http://panamapapers.sueddeutsche.de/articles/56febff0a1bb8d3c3495adf4/]]
    Relational database, network analysis, follow-the-money approach

    [[http://drones.pitchinteractive.com/]]
    Data-led storytelling

    [[http://www.jplusplus.org/en/project/rentswatch/]]
    Crowdfunding + scraping

    [[http://newsroom.tools/]]
    [[http://otranscribe.com/]]
    Journalism Tools

** Running your Pythons

*** solution one: the old way

   A Python script is a file, eg *example.py*

   You run this file through the **command line** with 

   #+BEGIN_SRC
   > `python example.py`
   #+END_SRC

*** wait what?
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/z8yYEX4pE3lkc/giphy.gif
    :reveal_background_trans: slide
    :END:
*** solution two: the notebook

    Python also comes with a set of utilities bundled in a GUI: [[http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb][the Jupyter Notebook]]

    We can run Python notebooks from the university computers.

    [[./images/jupyter.png]]

** To write code, you use a text editor

   [[https://www.sublimetext.com][for example, Sublime Text]]

   #+BEGIN_QUOTE
   Why not Word, Mac's TextEdit?
   #+END_QUOTE

   These softwares are word processors. They add _lots_ of code around the words you actually see on screen.

** Let's see some syntax
*** Variables
**** Strings

   #+BEGIN_SRC python
    variable = 'some text'

    print variable
    > some text
   #+END_SRC

**** Integers

   #+BEGIN_SRC python
    variable = 1

    print variable
    > 1
   #+END_SRC

*** Variables (2): Lists

   #+BEGIN_SRC python
    list= [1, 2, 'basile']

    print(list)
    > [1,2,'basile']

    print(list[0])
    > 1

    print(list[1])
    > 2
   #+END_SRC

*** Variables (3): Objects/dictionaries

   #+BEGIN_SRC python
    addresses = {'Mum': '07439487463', 'Donal Trump': '573-555-5555'}

    print(addresses['Mum'])
    > 07439487463
   #+END_SRC

*** Conditional execution: `if/else`

   #+BEGIN_SRC python
    name = 'basile'
    if name is 'basile'
       print('okay!')

    > okay!
   #+END_SRC

*** Conditional execution: `if/else` (2)

   #+BEGIN_SRC python
    number = 10
    if number > 5:
        print('Wow, that's a big number!')
   #+END_SRC

*** Booleans
    In Python, they are `True` and `False`

   #+BEGIN_SRC python
    1 == 1
    "test" != "testing"
    "test" == 1
   #+END_SRC

*** Control flow: `for` loop

   #+BEGIN_SRC python
    list_of_letters = ['a', 'b', 'c']

    for letter in list_of_letters:
        print(letter)
   #+END_SRC

*** Methods and functions

   #+BEGIN_SRC python
    def add_two(x):
        return x + 2

    var = 1
    print(var)
    > 1

    add_two(var)
    > 3

    add_two('basile')
    > ERROR
   #+END_SRC

** web scraping free text in python
    [[./images/guido.png]]

*** output

    This is a comma-separated values format, where every line in the file is a data record.

    [[https://en.wikipedia.org/wiki/Comma-separated_values]]

    #+BEGIN_SRC 
    MP,Party,Constituency
    Heidi Alexander ,Labour,Lewisham East
    Rushanara Ali ,Labour,Bethnal Green and Bow
    Mr Graham Allen ,Labour,Nottingham North
    Lyn Brown ,Labour,West Ham
    Chris Bryant ,Labour,Rhondda
    Ms Karen Buck ,Labour,Westminster North
    Dawn Butler ,Labour,Brent Central
    #+END_SRC

*** How?

    - Open the page
    - Fire up your DevTools
    - Tinker with the DOM to spot the consistency
    - Understand the tree structure to reach the elements you want

    Scraping is all about targeting the right element(s), and/or identifying the patterns in the document.
    
    Because through programming, patterns can be pried open and stripped bare, leaving only the relevant information.

*** Let's get scraping

    [[https://order-order.com/2017/02/08/named-122-mps-voted-brexit/]]
* 3.1: Simple scraping in Python
  :LOGBOOK:
  CLOCK: [2018-02-05 Mon 22:59]--[2018-02-06 Tue 00:50] =>  1:51
  CLOCK: [2018-02-04 Sun 22:10]--[2018-02-04 Sun 22:23] =>  0:13
  CLOCK: [2018-02-04 Sun 20:38]--[2018-02-04 Sun 22:00] =>  1:22
  :END:

** recap from last week
*** Python syntax

    #+BEGIN_SRC python
    # a variable
    foo = 'bar'

    # a list
    aList = [1,2,'lol']

    # an if statement
    if 'lol' in aList:
        print('element found')

    # a for loop
    for element in foo:
        if 'lol' is element:
            print element
            # > 'lol'
    #+END_SRC

*** web scraping with BeautifulSoup

    #+BEGIN_SRC python
    url = 'https://order-order.com/2017/02/08/named-122-mps-voted-brexit/'
    response = requests.get(url)

    # parses HTML
    html = response.content

    # magic method
    soup = BeautifulSoup(html, 'lxml')

    # now we can work
    soup.findAll('html elements')
    #+END_SRC

** scraping traitors
*** understanding the page structure
    
    - two <blockquote>
    - each contaning many <em>
    - each <em> containing our data points
 
*** mostly, it looks like so

    "name (party - constituency)"

    eg 

    #+BEGIN_SRC 
    Martyn Day (Scottish National Party – Linlithgow and East Falkirk)
    Maria Eagle (Labour – Garston and Halewood)
    #+END_SRC

*** problems

    - a few _Labour (Co-op)
    - one SNP- Inverness

    This is the key issue with web scraping: dirty data!

*** back to our notebook!
** scraping: recap

   - for each <em> in each <blockquote>
   - split the text in different ways to create our variables
   - add our variables to a list
   - add this list to another list (a list of list, then)
   - each list in our list of list is a row
   - write CSV file

** scraping: result!

   [[./img/results.png]]

** spotting traitors

   Now that we've got our 122 names we want to see who betrayed their constituency: jump to `spotting-traitors`

*** links we used
    
   - [[https://www.shanelynn.ie/merge-join-dataframes-python-pandas-index-1/#mergetypes][merge types]]
   - [[https://jeffdelaney.me/blog/useful-snippets-in-pandas/][useful pandas snippets]]

*** reading

    - [[https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python][more pandas, a course]]
  
* 3.2: More complex scraping in Python?
  :LOGBOOK:
  CLOCK: [2018-02-08 Thu 21:37]--[2018-02-08 Thu 21:41] =>  0:04
  CLOCK: [2018-02-08 Thu 20:18]--[2018-02-08 Thu 21:03] =>  0:45
  CLOCK: [2018-02-08 Thu 18:27]--[2018-02-08 Thu 19:08] =>  0:41
  CLOCK: [2018-02-06 Tue 22:04]--[2018-02-06 Tue 22:20] =>  0:16
  CLOCK: [2018-02-06 Tue 20:53]--[2018-02-06 Tue 21:22] =>  0:29
  CLOCK: [2018-02-06 Tue 18:34]--[2018-02-06 Tue 19:17] =>  0:43
  CLOCK: [2018-02-04 Sun 22:00]--[2018-02-04 Sun 22:10] =>  0:10
  :END:
  
** javascript exercise

   #+BEGIN_QUOTE
   Build an interactive thing in Javascript, that responds to a user input.
   #+END_QUOTE

** assessment update
   #+ATTR_REVEAL: :frag (appear)
   - still waiting on deadlines to be updated
   - are you clear on what the week 5 assessment is?
   - final project: two routes...

** two routes for the final project
   #+ATTR_REVEAL: :frag (appear)

   - option one: build a full website
   - option two: host your content on Medium/blog/Wordpress

   Obviously I will assess the two options differently, i.e.

   #+ATTR_REVEAL: :frag (appear)
   - if you do more website, front-end work, I will be kinder on the data work
   - if you do little website-building, your data work must be top notch!

** scraping, scraping!

*** web scraping v API

    [[https://www.grepsr.com/web-scraping-vs-api/][a simple comparison]]:

   #+ATTR_REVEAL: :frag (appear)
    - is an API available/hidden?
    - is the API actually up-to-date?
    - rate limiting
    - but better structure
   
   One thing to consider: the ethics of web scraping: see this recent [[https://www.eff.org/deeplinks/2018/01/ninth-circuit-doubles-down-violating-websites-terms-service-not-crime][Ninth Circuit ruling]] that violating a website's term of service is not a crime

*** web scraping

    [[https://blog.hartleybrody.com/web-scraping/][Every website can be scraped]]*

   #+ATTR_REVEAL: :frag (appear)
   * if you're good enough
   
   good practice: set headers in your web requests identifying yourself

   #+BEGIN_SRC python
   import requests
 
   headers = {'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5);
                Basile Simon/ London/ basile.simon@thetimes.co.uk'}
   html = requests.get(url, headers=headers)
   #+END_SRC

   [[https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe][A good tutorial]]

*** API scraping

    using an API is using an authorised service

** tools of the trade: the APIs

   [[https://www.theguardian.com/media/pda/2007/dec/14/thenutshellabeginnersguide][even the Guardian has a piece about "what's an API"]]

   #+BEGIN_QUOTE
   The exception are sites built on open source code, which is sort of like a *worldwide hippy commune* of developers who share their notes. The idea is that they can make better products and software if lots of people collaborate on a project.
   #+END_QUOTE

   good API example: [[https://postcodes.io/][postcodes.io]]

** setup
*** register on twitter

    - log into your twitter account
    - register your phone number with your account
    - click on your profile pic (top left-hand side), then head to "Mobile"

*** create your (first?) twitter app

    https://apps.twitter.com/

    that's a common way to keep control of who's allowed to use your service.
    this way, they can shut your app down [[https://www.theverge.com/2015/6/4/8731387/politwoops-sunlight-foundation-twitter][if you abuse your privileges]]

    [[./img/twitter-app-create.png]]
    
*** fill in application details

    [[./img/twitter-app-info.png]]

*** DO NOT publish your API keys etc.

    some people scrape the internet for published credentials. they could take over your account, post whatever they want in your name, including sending DMs. you've been warned.
** how to use an API?

   - read the documentation
   - find a convenient wrapper library that does the heavy lifting for you

   in our case: that's [[http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html][tweepy]], a wrapper library around the twitter API built in python.

*** installing tweepy

    #+BEGIN_SRC 
    pip3 install tweepy
    #+END_SRC

*** more modules

    #+BEGIN_SRC 
    pip3 install pandas numpy matplotlib seaborn
    #+END_SRC


    [[http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html][Getting started with tweepy]]

** notes from the session

   - [[https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe][what's a dataframe?]]
   - [[https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python][mostly everything about pandas dataframes]]
   - [[https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe][a Series is one column of a dataframe]]
   - [[https://medium.freecodecamp.org/series-and-dataframe-in-python-a800b098f68][series and dataframes, cont.]]
* 4.1: R in the newsroom: the tidyverse
  :LOGBOOK:
  CLOCK: [2018-02-13 Tue 22:24]--[2018-02-13 Tue 22:49] =>  0:25
  CLOCK: [2018-02-13 Tue 19:38]--[2018-02-13 Tue 20:32] =>  0:54
  CLOCK: [2018-02-10 Sat 15:08]--[2018-02-10 Sat 22:49] =>  7:41
  :END:

** JOM299 final project

   two routes:
   - build a full website to host your final project
   - host your piece on a blog/Medium
   
   for students picking option one...

*** here is a template!

    [[https://github.com/basilesimon/interactive-journalism-module/tree/master/website-template][see on Github]]

    HTML index file + CSS + Javascript from a web framework called Bootstrap.

    contains all the assets you'd need, with pre-defined CSS and style rules. Download, take the bits you don't want out, play with it as much as you like, and *try to re-use bits of it.*

    the purpose of that framework is to have you write as little basic CSS as possible!

** what is R

   R is a programming language very popular among statisticians, researchers, and data scientists.

   In addition to traditional data structures, R comes out of the box with regression models, time-series support, geo capabilities, and many stats shorthands.

   [[./images/R_logo.svg.png]]

** why R?

   FiveThirtyEight, Buzzfeed, The Times, The Guardian, some German newsrooms...

   for some reason R has gained popularity in newsrooms among data specialists

*** should I choose R or Python?

    no right answer to this question!
    R v Python: [[https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis][an infographic]]

   #+ATTR_REVEAL: :frag (appear)
   - many ways to write R: several schools of thought
   - Python is more consistent across users: meaningful indentation helps
   - you can do anything with Python, R is slightly more focused
   - Python online documentation/community is more beginner-friendly
   - pure salary from survey: R about +20% (one of the most top-paying languages)
   
    R isn't exactly the [[https://en.wikipedia.org/wiki/Zen_of_Python][Zen of Python...]]
    
** elements of syntax

*** the basics
    #+BEGIN_SRC R
    # a comment
    
    # a variable
    foo <- 'bar'
    
    # a list, called a 'vector'
    foo <- c(1, 2, 'lol')
    #+END_SRC

*** functions and for loops?

    the so-called "R way" is very much line-by-line, not that much oriented towards functions and iterators

    #+BEGIN_SRC R
    foo <- c(1, 3, 'some data', 'not to remove')
    foo_clean <- foo[-(1:2)]
    #+END_SRC

** the tidyverse

   there are several ways to write R. an important one follows Hadley Wickham's philosophy and work at RStudio.

   it is called *[[https://www.tidyverse.org/packages/][the tidyverse]*

   > The tidyverse is a coherent system of packages for data manipulation, exploration and visualization that share a common design philosophy

   [[./images/tidyverse1.png]]

*** tidy data

    [[https://hackyhour.github.io/Goettingen/slides/tidy_slides.html#/][principles of tidy data]], a presentation (built in RStudio!) from Wickham's paper [[http://vita.had.co.nz/papers/tidy-data.pdf]["Tidy Data"]]

*** a set of tools

    example: the pipe `%>%`

    #+BEGIN_SRC javascript
    const foo = [1,2,10];
    foo.forEach(function(element) {
      if (element > 2) {
        return element;
      }
    });
    #+END_SRC

    #+BEGIN_SRC R
    foo <- c(1,2,10)
    foo %>%
      filter( > 2)
    #+END_SRC

*** the pipe II

    > The operators pipe their left-hand side values forward into expressions that appear on the right-hand side, i.e. one can replace f(x) with x %>% f(), where %>% is the (main) pipe-operator. 

    #+BEGIN_SRC R
    the_data <-
      read.csv('/path/to/data/file.csv') %>%
      subset(variable_a > x) %>%
      transform(variable_c = variable_a/variable_b) %>%
      head(100)
    #+END_SRC

*** pipes and verbs

    #+BEGIN_SRC R
    cars <- cars %>%
      mutate(pounds = weight / 1000)
    #+END_SRC

** dplyr tutorial

   [[http://genomicsclass.github.io/book/pages/dplyr_tutorial.html]]

   - `select()`
   - `filter()`
   - `%>%`
   - `mutate()`
   - `group_by()`
  
*** let's put that into practice: civilian casualties from Coalition bombings

    Data from airwars.org

** reading

   - [[https://rpubs.com/aelhabr/tidyverse-basics][the super helpful cheatsheets]]
   - [[https://tidyverse-intro.github.io/index.html][everything you could want to know about the tidyverse in a handy tutorial]]
   - [[https://pandas.pydata.org/pandas-docs/stable/comparison_with_r.html][pandas v the tidyverse syntax]]
   - [[https://www.datacamp.com/courses/introduction-to-the-tidyverse][Datacamp tidyverse course]]
   - [[http://r4ds.had.co.nz/exploratory-data-analysis.html][exploratory data analysis]]
  
* 4.2: R in the newsroom: scrapin' and cleanin'
  :LOGBOOK:
  CLOCK: [2018-02-15 Thu 23:00]--[2018-02-15 Thu 23:32] =>  0:32
  CLOCK: [2018-02-15 Thu 19:28]--[2018-02-15 Thu 20:05] =>  0:37
  CLOCK: [2018-02-15 Thu 18:18]--[2018-02-15 Thu 19:27] =>  1:09
  CLOCK: [2018-02-11 Sun 17:45]--[2018-02-11 Sun 18:08] =>  0:23
  :END:
  
** the task

  #+BEGIN_QUOTE
  We need a poll of polls for the Italian election. By yesterday, please, chop chop.
  #+END_QUOTE
  an editor who realises we're two weeks away from an election

** the output

   [[./images/pop.png]]

*** well, not quite...

   [[./images/Rplot.png]]

** the source
   
   We need a data source for the polls.

   There is an official source, which is an ASPX app that looked too daunting.

   Easy-looking one: [[https://en.wikipedia.org/wiki/Opinion_polling_for_the_Italian_general_election,_2018#Graphical_summary][a Wikipedia table]]

   So what do we have here?

   #+ATTR_REVEAL: :frag (appear)
   - a <table> element
   - several, actually!
   - contains all the polling from different institutes
  
** scraping the source

   #+BEGIN_SRC R
   # install.packages('rvest')
   library(rvest)

   url <- 'https://a-url.com'
   df <- url %>%
         read_html() %>%
         html_node(xpath="an/xpath/") %>%
         html_table()
   #+END_SRC

*** example
  
   #+BEGIN_SRC R
   url <- 'https://en.wikipedia.org/wiki/List_of_rampage_killers_(school_massacres)'
   url %>% read_html() %>%
      html_node(xpath='/html/body/div[3]/div[3]/div[4]/div/table[4]') %>%
      html_table() %>%
      View()
   #+END_SRC

*** problems for us

   #+ATTR_REVEAL: :frag (appear)
   - our columns are all messed up!
   - oh, also our numbers look like strings?!

** cleaning our data

   #+ATTR_REVEAL: :frag (appear)
   - our dates aren't going to be practical to work with
   - too many columns
   - not a tidy representation of data

   #+ATTR_REVEAL: :frag (appear)
   **Rule of thumb for dates**: the closer to YYYY-MM-DD you are the easier it will be to convert to a proper date

*** this horrible code

  #+BEGIN_SRC R
  mutate(cut_date = paste(tail(strsplit(date, "–")[[1]], n=1), " 2018")) %>%
  mutate(clean_date = as.Date(cut_date, format="%d %b %Y"))
  #+END_SRC

  #+BEGIN_SRC R
  foo = "2-7 Feb"
  strsplit(foo, "-")[[1]]   -> list: ["2", "7 Feb"]
  tail(the_above), n=1)     -> "7 Feb"
  paste(the_above, " 2018") -> "7 Feb 2018"
  as.Date(the_above, format="%d %b %Y")  is a win!
  #+END_SRC

*** melting our data into tidy format

    this is what we have:

    |       date | firm | party one | party two | party three | etc |
    | 2017-01-01 | ipso |        24 |        32 |          10 | n   |
    | 2017-01-02 | ipso |        22 |        31 |           9 | n   |

*** melting our data into tidy format
    
    this is what we want:

    |       date | party | value |
    | 2017-01-01 | one   |    24 |
    | 2017-01-01 | two   |    32 |
    | 2017-01-01 | three |    10 |
    | 2017-01-02 | one   |    22 |
    | 2017-01-02 | two   |    31 |
    | 2017-01-02 | three |     9 |

*** the solution: melt()

    [[http://seananderson.ca/2013/10/19/reshape.html][melt()]]

** visualising our data

   `ggplot` is awesome.

   #+BEGIN_SRC R
   # install.packages('ggplot2')
   library(ggplot2)

   ggplot(data, aes( x = a_column, y = another_column )) +
     geom_point() +
     geom_bar()
   #+END_SRC

   dataset + aesthetics (which bit of the data goes where) + coordinate system + geometries

** adding value to our data to answer a question

   #+BEGIN_QUOTE
   How well do we think these parties are doing, from these very different polls, and over time?
   #+END_QUOTE

   #+ATTR_REVEAL: :frag (appear)
   sounds like a job for avering things out.

*** merging data

    our two datasets having been prepared in the same way, with the same column names... the merge is super easy:

    #+BEGIN_SRC R
    merge(dataframe_1, dataframe_2)
    #+END_SRC

    normally, you'd do:

    #+BEGIN_SRC R
    merge(dataframe_1, dataframe_2, by="id")
    #+END_SRC

    where "id" is a column the two datasets share (remember how we merged on the constituency names for the MPs, in Python...)

*** averaging

    #+BEGIN_SRC R
    rollapply(value, width = 20,
       fill = NA, partial = TRUE, 
       FUN=function(x) mean(x, na.rm=TRUE),
       align = "right")
    #+END_SRC

** more

  - [[http://genomicsclass.github.io/book/pages/dplyr_tutorial.html][dplyr tutorial]]
  - [[https://tidyverse-intro.github.io/index.html][everything you could want to know about the tidyverse in a handy tutorial]]
 
* 5.1: R in the newsroom: ggplot
  :LOGBOOK:

  CLOCK: [2018-02-20 Tue 18:35]--[2018-02-20 Tue 18:55] =>  0:20
  CLOCK: [2018-02-17 Sat 15:30]--[2018-02-17 Sat 16:12] =>  0:42
  :END:

** presentations

   Remember the rules:

   #+ATTR_REVEAL: :frag (appear)
   - 3-minute presentation
   - slides/presentation optional but recommended
   - question(s) at the end
   - 500-word brief submitted yesterday by 5pm

** what is ggplot?

   [[http://ggplot2.org/resources/2007-vanderbilt.pdf][the founding paper (pdf)]]

   #+BEGIN_QUOTE
   1. dataset + 
   2. geometries + 
   3. coordinate system
   == all you need to make a chart!
   #+END_QUOTE

** loading some data

  #+BEGIN_SRC R
  library(readr)
  library(dplyr)
  library(ggplot2)
  
  data <- read_csv("https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/exercise/data.csv")
  data %>% View()
  #+END_SRC

** what is that dataset?

   | SIC07 | description      | number                    | degrees                                   | mean        |
   |       | work description | number of people employed | percentage of secondary education degrees | mean income |

** basic plot

   we pass our dataset data and define the aesthetics: an x and y axis:

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees)) +
       geom_point()
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-2-1.png]]

*** Make the bubble size represent the number of people in this field

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number)) +
       geom_point()
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-3-1.png]]

*** Make the bubbles bigger by setting a maximum

   we can reuse the previous chart we built, simply adding a layer with the plus (+) sign:

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number)) +
       geom_point() +
       scale_size_area(max_size = 15)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-4-1.png]]

*** Add a progressive colour scale depending on the number of people

   that's a new property called `fill`. It will assign default colours for you.

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-5-1.png]]

*** Make our axis prettier and more sensible

   again, re-using our previous chart, we set two additional layers that apply to the axis:

   #+BEGIN_SRC R
   library(scales)
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-6-1.png]]

*** A logarithmic y-axis, maybe?

   useful for visualising extreme value differences: https://datavizblog.com/2013/03/26/how-to-visualize-data-with-extreme-value-differences/

   #+BEGIN_SRC R
   library(scales)
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent, trans=log2_trans())
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-7-1.png]]

*** Add labels so we can see clearer... or not

   note both the label property in the aesthetics and the geom_text() layer.

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number, label=Description)) +
       geom_point(shape=21) +
       scale_size_area(max_size = 15) +
       #scale_y_continuous(trans=log2_trans()) +
       geom_text(size = 2)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-8-1.png]]

** let's load some annotated data

   #+BEGIN_SRC R
   data_annotated <- read_csv("https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/exercise/data_annotated.csv")
   df <- data_annotated
   #+END_SRC

*** Colour the privileged gigs depending on annotation

  #+BEGIN_SRC R
  ggplot(df, aes(x = Mean, y = Degrees, size = Number, fill=Category)) +
      geom_point(shape=21) +
      scale_size_area(max_size = 15) +
      scale_x_continuous(breaks = seq(0, 70000, 10000)) +
      scale_y_continuous(labels = scales::percent, trans=log2_trans())
  #+END_SRC

  [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-10-1.png]]

*** Add some text annotation to the plot

   we add two annotation layers with annotate(), with some x/y coordinates and which text to render.

   #+BEGIN_SRC R
   colors <- ggplot(df, aes(x = Mean, y = Degrees, size = Number, fill=Category)) +
       geom_point(shape=21) +
       scale_size_area(max_size = 15) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent, trans=log2_trans())
       annotate("text", x = 40000, y = .55, label = "Privileged gigs") +
       annotate("text", x = 20000, y = .2, label = "Precarious gigs")
   colors
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-11-1.png]]

*** "Annotation are the core of what we do" - Amanda Cox

   #+BEGIN_SRC R
   finalPlot <- colors +
      annotate("text", x = 31500, y = .05, label = "Construction and building") +
      annotate("text", x = 12000, y = .52, label = "Education") +
      annotate("text", x = 43500, y = .85, label = "Health sector") +
      annotate("text", x = 10000, y = .15, label = "Hairdressers") +
      annotate("text", x = 12000, y = .39, label = "Sports and recreation") +
      annotate("text", x = 21000, y = .7, label = "Arts") +
      annotate("text", x = 40000, y = .35, label = "Real estate") +
      annotate("text", x = 14000, y = .08, label = "Taxis") +
      annotate("text", x = 36000, y = .7, label = "IT and programming") +
      annotate("text", x = 48000, y = .59, label = "Consultancies") +
      annotate("text", x = 18000, y = .24, label = "Retail") +
      annotate("text", x = 58000, y = .85, label = "Legal and accounting")
   finalPlot
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-12-1.png]]

** fun with themes

  #+BEGIN_SRC R
  library(ggthemes)
  finalPlot + theme_minimal()
  #+END_SRC

  #+BEGIN_SRC R
  finalPlot + theme_economist() + scale_colour_economist()
  #+END_SRC

  #+BEGIN_SRC R
  finalPlot + theme_solarized() +
  scale_colour_solarized("blue")
  #+END_SRC

** facetting

   #+BEGIN_SRC R
   finalPlot + facet_grid(. ~ Category)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-17-1.png]]

** reading and homework

   https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen
   
   http://datadrivenjournalism.net/resources/when_should_i_use_logarithmic_scales_in_my_charts_and_graphs

   https://www.datacamp.com/community/blog/the-easiest-way-to-learn-ggplot2#gs.QnUNY8Y

* 5.2: Some stats in R
  :LOGBOOK:
  CLOCK: [2018-02-22 Thu 22:13]--[2018-02-22 Thu 22:45] =>  0:32
  CLOCK: [2018-02-21 Wed 16:40]--[2018-02-21 Wed 18:26] =>  1:46
  CLOCK: [2018-02-21 Wed 10:40]--[2018-02-21 Wed 12:40] =>  2:00
  CLOCK: [2018-02-20 Tue 22:27]--[2018-02-21 Wed 00:57] =>  2:30
  CLOCK: [2018-02-20 Tue 18:35]--[2018-02-20 Tue 20:28] =>  1:53
  :END:

** presentations

   Remember the rules:

   #+ATTR_REVEAL: :frag (appear)
   - 3-minute presentation
   - slides/presentation optional but recommended
   - question(s) at the end
   - 500-word brief submitted yesterday by 5pm
** loading some data

  #+BEGIN_SRC R
  library(readr)
  library(dplyr)
  library(ggplot2)
  
  data <- read_csv("https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/exercise/data.csv")
  data %>% View()
  #+END_SRC

** what is that dataset?

   | SIC07 | description      | number                    | degrees                                   | mean        |
   |       | work description | number of people employed | percentage of secondary education degrees | mean income |

** basic plot

   we pass our dataset data and define the aesthetics: an x and y axis:

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees)) +
       geom_point()
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-2-1.png]]

*** Make the bubble size represent the number of people in this field

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number)) +
       geom_point()
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-3-1.png]]

*** Make the bubbles bigger by setting a maximum

   we can reuse the previous chart we built, simply adding a layer with the plus (+) sign:

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number)) +
       geom_point() +
       scale_size_area(max_size = 15)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-4-1.png]]

*** Add a progressive colour scale depending on the number of people

   that's a new property called `fill`. It will assign default colours for you.

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-5-1.png]]

*** Make our axis prettier and more sensible

   again, re-using our previous chart, we set two additional layers that apply to the axis:

   #+BEGIN_SRC R
   library(scales)
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-6-1.png]]

*** A logarithmic y-axis, maybe?

   useful for visualising extreme value differences: https://datavizblog.com/2013/03/26/how-to-visualize-data-with-extreme-value-differences/

   #+BEGIN_SRC R
   library(scales)
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number)) +
       scale_size_area(max_size = 15) +
       geom_point(shape=21) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent, trans=log2_trans())
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-7-1.png]]

*** Add labels so we can see clearer... or not

   note both the label property in the aesthetics and the geom_text() layer.

   #+BEGIN_SRC R
   ggplot(data, aes(x = Mean, y = Degrees, size = Number, fill=Number, label=Description)) +
       geom_point(shape=21) +
       scale_size_area(max_size = 15) +
       #scale_y_continuous(trans=log2_trans()) +
       geom_text(size = 2)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-8-1.png]]

** let's load some annotated data

   #+BEGIN_SRC R
   data_annotated <- read_csv("https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/exercise/data_annotated.csv")
   df <- data_annotated
   #+END_SRC

*** Colour the privileged gigs depending on annotation

  #+BEGIN_SRC R
  ggplot(df, aes(x = Mean, y = Degrees, size = Number, fill=Category)) +
      geom_point(shape=21) +
      scale_size_area(max_size = 15) +
      scale_x_continuous(breaks = seq(0, 70000, 10000)) +
      scale_y_continuous(labels = scales::percent, trans=log2_trans())
  #+END_SRC

  [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-10-1.png]]

*** Add some text annotation to the plot

   we add two annotation layers with annotate(), with some x/y coordinates and which text to render.

   #+BEGIN_SRC R
   colors <- ggplot(df, aes(x = Mean, y = Degrees, size = Number, fill=Category)) +
       geom_point(shape=21) +
       scale_size_area(max_size = 15) +
       scale_x_continuous(breaks = seq(0, 70000, 10000)) +
       scale_y_continuous(labels = scales::percent, trans=log2_trans())
       annotate("text", x = 40000, y = .55, label = "Privileged gigs") +
       annotate("text", x = 20000, y = .2, label = "Precarious gigs")
   colors
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-11-1.png]]

*** "Annotation are the core of what we do" - Amanda Cox

   #+BEGIN_SRC R
   finalPlot <- colors +
      annotate("text", x = 31500, y = .05, label = "Construction and building") +
      annotate("text", x = 12000, y = .52, label = "Education") +
      annotate("text", x = 43500, y = .85, label = "Health sector") +
      annotate("text", x = 10000, y = .15, label = "Hairdressers") +
      annotate("text", x = 12000, y = .39, label = "Sports and recreation") +
      annotate("text", x = 21000, y = .7, label = "Arts") +
      annotate("text", x = 40000, y = .35, label = "Real estate") +
      annotate("text", x = 14000, y = .08, label = "Taxis") +
      annotate("text", x = 36000, y = .7, label = "IT and programming") +
      annotate("text", x = 48000, y = .59, label = "Consultancies") +
      annotate("text", x = 18000, y = .24, label = "Retail") +
      annotate("text", x = 58000, y = .85, label = "Legal and accounting")
   finalPlot
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-12-1.png]]

** fun with themes

  #+BEGIN_SRC R
  library(ggthemes)
  finalPlot + theme_minimal()
  #+END_SRC

  #+BEGIN_SRC R
  finalPlot + theme_economist() + scale_colour_economist()
  #+END_SRC

  #+BEGIN_SRC R
  finalPlot + theme_solarized() +
  scale_colour_solarized("blue")
  #+END_SRC

** facetting

   #+BEGIN_SRC R
   finalPlot + facet_grid(. ~ Category)
   #+END_SRC

   [[https://raw.githubusercontent.com/basilesimon/interactive-journalism-module/archive/2016-2017/week6/week6-figure/unnamed-chunk-17-1.png]]

** fun with the Italian election of 2013

   We're going to plot the results in each of the 101 districts against some indicators:

   - levels of migration
   - number of patents per 10,000 inhabitants
   - and Purchasing Power Standard

** reading and homework

   https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen
   
   http://datadrivenjournalism.net/resources/when_should_i_use_logarithmic_scales_in_my_charts_and_graphs

   https://www.datacamp.com/community/blog/the-easiest-way-to-learn-ggplot2#gs.QnUNY8Y


