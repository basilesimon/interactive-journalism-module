#+Title: JOM299
#+Author: Basile Simon
#+Email: @basilesimon

#+OPTIONS: toc:nil num:nil
#+OPTIONS: reveal_width:1200
#+OPTIONS: reveal_height:800
#+REVEAL_MARGIN: 0.1
#+REVEAL_MIN_SCALE: 0.5
#+REVEAL_MAX_SCALE: 2.5
#+OPTIONS: reveal_center:nil 
#+OPTIONS: reveal_rolling_links:t reveal_keyboard:t reveal_overview:t 
#+OPTIONS: org-html-indent:nil
#+REVEAL_TRANS: linear
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Title">
#+REVEAL_ROOT: http://cdn.jsdelivr.net/reveal.js/3.0.0/
#+REVEAL_EXTRA_CSS: ../presentation/mozilla-devrel-light.css
#+REVEAL_PLUGINS: (highlight)
#+REVEAL_HLEVEL: 2


* TODO teaching plan
** Week 1 - The basics

  The mysterious creature that is the DOM, what a webpage actually is, and using the DevTools.  

  We'll have a look at the very basics of working with the web. Having done the pre-course work (Codecademy Javascript tutorial), we hopefully won't lost much time. No set-up involved, just simple practical exercises in a web browser

*** Session 1: practical exercises
*** Session 2: more exercises

** Week 2 - Working with Python and data

  A foundation session in which we'll talk about some basics such as file formats and, er, where do you write code in the first place. We'll rattle through some online resources and communities where you can get help if you're stuck with a problem.
  During the second session we'll see the basics of the Python programming language.

*** Session 1: file formats, writing code, exploratory data analysis
*** Session 2: intro to Python

** Week 3 - Concrete scraping examples in Python

  A heavy session made up of short examples we'll study and extract data from.

*** Session 1: simple scraping
*** Session 2: more complex scraping, saving data

** Week 4 - R in the newsroom

  Armed with our new best friend RStudio, we'll introduce the R programming language and explore the fantastic `tidyverse`, as well as plotting our first charts.

*** Session 1: the tidyverse
*** Session 2: ggplot

** Week 5 - Concrete R exercises

  We'll touch on statistics concepts and keep proving how great R is at prototyping and wrangling data and charts.

*** Session 1: data cleaning exercises
*** Session 2: enough stats to keep you out of trouble

** Week 6 - More R
   
  ???

** Week 7 - Into Javascript charts world

  An overview of what is data viz and how central D3.js is to the discipline. We'll however pivot quickly towards Highcharts.js for its simplicity. As for the R sessions, we'll work through basic plotting then more complex examples.

*** Session 1: overview of the discipline, Highcharts
*** Session 2: Highcharts + misc explorations

** Weeks 8, 9, 10 - Project work

  We will go round the room and take questions from students about their final project. Come prepared with actual problems, be happy to work collaboratively and to make progress in class while we tackle challenges collectively, on the big screen. These sessions are usually the time when "ha-ha" moments happen.


* moodle
  :LOGBOOK:
  CLOCK: [2018-01-18 Thu 11:32]--[2018-01-18 Thu 11:55] =>  0:23
  :END:
** DONE week-by-week outline
   CLOSED: [2018-01-18 Thu 11:55]

* 1.1: The basics
  :LOGBOOK:
  CLOCK: [2018-01-23 Tue 22:45]--[2018-01-23 Tue 23:04] =>  0:19
  CLOCK: [2018-01-23 Tue 17:51]--[2018-01-23 Tue 18:29] =>  0:38
  CLOCK: [2018-01-18 Thu 20:31]--[2018-01-18 Thu 20:56] =>  0:25
  CLOCK: [2017-12-27 Wed 16:00]--[2017-12-27 Wed 16:39] =>  0:39
  :END:
** module information
   Module code: JOM299
   Title: Advanced Data and Coding

   - Module and assessment outline
   - The self-learner attitude
   - Useful resources
   - Intro to the DevTools, the DOM, and debugging your things
** topics covered in this module
   - Introduction to programming and the web with Javascript
   - Basic web scraping with Python
   - Exploratory analysis and day-to-day work with R
   - Putting charts on the web
** module outline and goals according to the spec
   - Develop a *complex skillset*
   - Gain an *understanding of data* and of modern digital journalism
   - Develop a *problem-solving philosophy*
   - Acquire *self-direction in learning*

** and I add to this:
 *Have a crucial advantage over others in the industry*

** assessment: mark split between...
*** 25% presentation and brief
   Will take place on *week 5*

   i.e.
- Wed 21 
- or Fri 23
*** 75% final project
   mid-April?
** cherry on top: build in JS week 3
    #+BEGIN_QUOTE
    Build a simple interactive thing, in Javascript. This can be a series of buttons on which to click to change a displayed information, for example. The action triggered will involve a function. Example: display "1". Upon clicking this button, a function adds 2 and displays "3". Ask the user for a number to add, display the result of 3+n.
    #+END_QUOTE

   We'll talk about this project in class

** assessment two: final project
    
   #+BEGIN_QUOTE
   Your project should identify and solve a journalistic problem, using data and coding work. Typically this will focus on a story -- either a complete story or an interactive feature forming part of a story. It could also be something for use in a newsroom (eg a tool helpful to journalists). 
   #+END_QUOTE

   that's from the course specs

** more about the final project
   Your project must be relevant to journalism (see above), operate at a functional level (at least as a working prototype), and involve all of the following:

   - data techniques, involving scraping, cleaning, analysis and/or presentation, as needed/appropriate to your project
   - adding value through user interactivity
   - use and modification of html, CSS, Javascript, Python, R, d3 
   - and/or other code (not simply plug-and-play elements)
   - use of free and/or low-cost tools
   - problem-solving.

   (that's also from the spec)

** the self-learner attitude - what is that?
   I want you to engage in the community of data-journalists, news hackers and tinkerers

   - [[https://news.ycombinator.com/item?id=13148319][Tips for self-learning (Hacker News)]]
   - [[https://www.reddit.com/r/dataisbeautiful/][/r/dataisbeautiful community]]
   - [[http://newsnerdery.org/][News Nerdery (Slack)]]
   - RSS feeds, Twitter...

** without further ado...
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/26uf6o80xhd6MKGIw/giphy.gif
    :reveal_background_trans: slide
    :END:

** what is the DOM?
   [http://domenlightenment.com/#1.1]

   #+BEGIN_QUOTE
   The DOM is a hierarchy/tree of Javascript node objects
   #+END_QUOTE

   - It looks like the HTML you wrote
   - It actually is the programming interface around it

** programming interface?
   #+BEGIN_SRC html
   <body>
     <article>
       <h1>This is a simple title</h1>

       <h1 id="special">This is another title... 
         <em>with a twist!</em>
       </h1>
     </article>
   </body>
   #+END_SRC

   Let's have a look: [[http://codepen.io/basilesimon/pen/PWNXEK][Codepen]]

** wait, console.log()?
   #+ATTR_REVEAL: :frag (appear)
   The Dev Tools: the Swiss army knife of web work

   What you can do with Dev Tools:
   - Edit the DOM directly
   - Change styles of any page
   - See Javascript code and errors
   - See and edit any file loaded by the page

** let's access the Dev Tools
   On Chrome and Firefox
   - `Ctrl` + `Shift` + `I` 
   - or `Cmd` + `Opt` + `I` on a Mac

** do things with the Dev Tools
   Inspect and edit pages and style: 
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/][exercise one]]
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/edit-styles][exercise two]]
   - [[https://developers.google.com/web/tools/chrome-devtools/inspect-styles/edit-dom][exercise three]]

** editing HTML with the Dev Tools
   Example: make Donald Trump say anything with the Dev Tools!

** hiding things with the Dev Tools
   Example: hide something on the [[https://www.google.co.uk/][Google homepage]]

** homework
-  [[http://codepen.io/basilesimon/pen/BQgwxG?editors=1100#0][Fix these images]]
-  [[http://codepen.io/basilesimon/pen/PWjJwg][Hide DOM elements]]
-  [[http://discover-devtools.codeschool.com/chapters/1?locale=en][Play with the dom]]

* 1.2: More exercises
  :LOGBOOK:
  CLOCK: [2018-01-25 Thu 20:21]--[2018-01-25 Thu 23:51] =>  3:30
  CLOCK: [2018-01-18 Thu 21:24]--[2018-01-18 Thu 21:32] =>  0:08
  CLOCK: [2018-01-15 Mon 20:54]--[2018-01-15 Mon 21:29] =>  0:35
  CLOCK: [2018-01-15 Mon 20:30]--[2018-01-15 Mon 20:54] =>  0:24
  CLOCK: [2017-12-27 Wed 16:39]--[2017-12-27 Wed 16:54] =>  0:15
  :END:
** useful links
   - [[https://www.thetimes.co.uk/article/digital-news-work-experience-qmg8f9585][The Times and Sunday Times work experience]]
   [[https://www.theguardian.com/gnmeducationcentre/journalism-work-experience-opportunities-young-people][- The Guardian work experience]]
** final projects
   [[https://ellawilksharper.github.io/a-day-in-the-life-of-mps/]]
   [[https://nellmooney.github.io/thecasting/]]
   [[https://alexandrama.github.io/trump-frequent-mentions/]]
** recap from last session
   #+ATTR_REVEAL: :frag (appear)
   - what is the DOM: a tree-like structure and a programming interface around it
   - HTML structures
   - Basics of Javascript: our way to interact with the DOM (among others)
   
   #+ATTR_REVEAL: :frag (appear)
   Let's have a look: [[http://codepen.io/basilesimon/pen/PWNXEK][Codepen]]

** picking up the homework: exercise 1

-  [[http://codepen.io/basilesimon/pen/BQgwxG?editors=1100#0][Fix these images]]

*** Image one: spot the typo
    #+BEGIN_SRC html
    <img src="http://some-url/image.jpg" />
    #+END_SRC

    #+BEGIN_SRC html
    <img scr="http://some-url/image.jpg" />
    #+END_SRC

    we want `src=...`, not `scr=...` - pay attention to typos!
*** Image two
    missing closing bracket `>`

    #+BEGIN_SRC
    // bad
    <img src="http://some-url/image.jpg"
    #+END_SRC

    #+BEGIN_SRC html
    // good
    <img src="http://some-url/image.jpg" />
    #+END_SRC
*** Image three: all good
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/d31x1fB3jEBvQ7E4/giphy.gif
    :reveal_background_trans: slide
    :END:

** picking up the homework: exercise 2
*** "how to hide div css" google search

    [[https://www.sitepoint.com/five-ways-to-hide-elements-in-css/][google search]]

*** solution
   #+BEGIN_SRC css
   #toHide { visibility: hidden; }
   #+END_SRC

   or

   #+BEGIN_SRC css
   #toHide { display: none; }
   #+END_SRC

** codecademy homework
** what's a variable?

   A variable is a store, in which you can put different data:
   #+ATTR_REVEAL: :frag (appear)
   - your age (a number)
   - your name (a string)
   - the result of a logical operation (true/false)
   
   #+BEGIN_SRC js
   var myAge = 26;
   var myName = "Basile";
   var doITeachAtCity = true;
   #+END_SRC

** what are the different data types?
   #+ATTR_REVEAL: :frag (appear)
   - *string*: takes quotation marks around it. example: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var name = "basile"; var age = "30";
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *number*: no quotation marks. example: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var number = 10; var budget = 1245.5;
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *boolean*: logical operators: 
   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var basileIsHere = true; var basileIsShaved = false;
   #+END_SRC
   #+ATTR_REVEAL: :frag (appear)
   - *array/list* (more later)
   - *object* (more later)
   - *null/undefined*
** data types: lists/arrays
   #+BEGIN_SRC js
   var thisIsAList = [1,2,3,'basile'];
   #+END_SRC

   contained between brackets, they store items in them. we can access these items like so:

   #+BEGIN_SRC js
   thisIsAList[0] // 1
   thisIsAList[3] // 'basile'
   #+END_SRC

   Note: lists are said 'zero-padded'
** data types: objects
   #+BEGIN_SRC js
   var thisIsAnObject = { name: 'basile', age: 26 };
   #+END_SRC

   kind of like lists, but object items can be accessed by their key, like so:

   #+BEGIN_SRC js
   console.log(thisIsAnObject.name); // 'basile'
   console.log(thisIsAnObject.age); // 26
   #+END_SRC

** what we use data types for

   different data have different use cases.

   #+ATTR_REVEAL: :frag (appear)
   - text is obviously a **string**
   - if you try to plot numbers on a chart or do maths, you better use **numbers**, not strings
   - **booleans** will be useful to do logical checks, e.g. "show me all MPs whose age is over 60"

** what we use data types for (repeat)

   different data have different use cases.

   #+ATTR_REVEAL: :frag (appear)
   - **lists** can be *iterated over*, i.e. "for each element in this list, do that"
   
     think of an Excel column with a formula that you drag down to apply it to all cells
   #+ATTR_REVEAL: :frag (appear)
   - **objects** are excellent *data stores* and more rich than so-called *flat* lists

** the for loop
   very useful pattern: `for` iterates over list items.

   #+ATTR_REVEAL: :frag (appear)
   #+BEGIN_SRC js
   var myList = [1,2,10,37];

   myList.forEach(function(element) {
     console.log(element);
     console.log(element + 1);
   }
   // 1, 2, 10, 37
   // 2, 3, 11, 38
   #+END_SRC

   #+ATTR_REVEAL: :frag (appear)
   - for each item  in my array,
   - log the said item plus one.

** the function

   functions are used to break down your code into separate, simple tasks

   #+BEGIN_SRC js
   function sayMyName(name) {
     console.log('HELLO' + name);
   };
   sayMyName('basile') // HELLO basile
   #+END_SRC

** the function (repeat)
   iterating over an array with a function

   #+BEGIN_SRC js
   // define a function like so
   function applyFunction(takesAVariableIn) {
     console.log(takesAVariableIn + ' is great'!
   }

   // define a variable, an array/list in this case
   var thisIsAVariable = ['basile', 'city uni'];

   // for each element of the array, run the function
   thisIsAVariable.forEach(function(element) {
     applyFunction(element);
   })
   #+END_SRC

** writing code: online code editors
   
   Purpose: no need to put files on your computer
   Just write code and go

   Tip: you might need the devtools to see your javascript!
   
   - JSBin
   - Codepen

** let's have a look 
   [[https://codepen.io/basilesimon/pen/GybzoE?editors=1010#0]]
   [[https://codepen.io/basilesimon/pen/XVLOXv?editors=1010]]
** online code editor demo: week 3 project
** examples
   https://codepen.io/basilesimon/pen/xpmGmN?editors=1010

** let's practice
   
   an addition I made yesterday to my dataviz catalogue for the Times:

   [[https://github.com/times/dataviz-catalogue/pull/28]]

   practice: https://codepen.io/basilesimon/pen/MrMNXX

   #+ATTR_REVEAL: :frag (appear)
   [[https://codepen.io/basilesimon/pen/ppXGBz]]

** homework
* 2.1: File formats, writing code
  :LOGBOOK:
  CLOCK: [2018-01-29 Mon 22:52]--[2018-01-30 Tue 00:25] =>  1:33
  CLOCK: [2018-01-29 Mon 18:45]--[2018-01-29 Mon 19:30] =>  0:45
  CLOCK: [2018-01-27 Sat 16:42]--[2018-01-27 Sat 19:42] =>  3:00
  CLOCK: [2018-01-18 Thu 12:07]--[2018-01-18 Thu 13:33] =>  1:26
  :END:

** file formats

   as for scripts (instructions) and web pages, we sometimes need to store data in files ("datasets").

   that's what you'd get from the ONS, data.gov.uk, an API, etc.

   there are different file formats for different purposes.

** file formats: CSV

   standing for Comma-Separated Values, CSV will be of much use to us when it comes to data.

   #+BEGIN_SRC
   myfile.csv
   #+END_SRC

   think of a spreadsheet without any formatting: 
   * every line in the file is a row,
   * every comma-separated value is a cell

*** CSV structure

   #+BEGIN_SRC
   name, occupation, height
   basile, journalist, 187
   donald, politician, 188
   #+END_SRC

** file formats: JSON

   standing for JavaScript Object Notation, JSON is almost universally used on the web.

   #+BEGIN_SRC
   myfile.json
   #+END_SRC

   structure in objects (`var anObject = {};`) separated by commas.
   made up of `key: value` pairs.

*** JSON structure

   #+BEGIN_SRC
   var json = {
     "name": "Basile Simon",
     "occupation": "journalist",
     "friends": [ "pierre", "donald", "theresa"]
   }
   #+END_SRC

   #+BEGIN_SRC
   json.name => "Basile Simon"
   json.friends[0]` => "pierre"
   #+END_SRC

   https://codepen.io/basilesimon/pen/MrZWZg?editors=1010#

** JSON and CSV in this course

   we're likely to store data when scraping, cleaning, etc. in CSV format.
   we'll probably use, or "parse" CSV data into JSON for the web.

   d3.js has a CSV parser: from the CSV above

   #+BEGIN_SRC
   name, occupation, height
   basile, journalist, 187
   donald, politician, 188
   #+END_SRC

   we parse it as JSON, so we can run `data.name` and get "basile" back

** file formats: Excel, databases

   Excel/ Google Spreadsheets are **visual representations** or CSV data

   Databases come with, as the DOM does, their programming interface and language (eg SQL)

** a word about Python
** Python
   
    Python is a programming language created in 1991.

    It is the most taught programming language around the world.

*** Why Python?

    Newsroom use: https://www.poynter.org/news/introduction-newsroom-programming-technologies

    Python is very easy to read and to use - and many newsrooms use it.

    **If you can write Python, you can write anything.**
   
** What Python looks like

    **Javascript**
    #+BEGIN_SRC js
    var foo = 'bar';
    function myFunction(parameter) {
      console.log(parameter);
    };
    #+END_SRC

    **Python**
    #+BEGIN_SRC python
    foo = 'bar'
    def myFunction(parameter):
        print(parameter)
    #+END_SRC

** running your pythons: the notebook
    
    Python also comes with a set of utilities bundled in a GUI: [[http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb][the Jupyter Notebook]]

    We can run Python notebooks from the university computers.

    [[./images/jupyter.png]]

** data wrangling in Python
*** white house visitors
*** school earnings
** links
   
   [[https://plot.ly/python/ipython-notebook-tutorial/][A good notebook tutorial]]
   [[https://plot.ly/python/getting-started/][Plots in Python with Plotly (easy)]]
   [[http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.1/cookbook/Chapter%205%20-%20Combining%20dataframes%20and%20scraping%20Canadian%20weather%20data.ipynb][An excellent notebook with scraping and plotting]]
   [[https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/][Advanced data science methods]]

* 2.2: An intro to Python
  :LOGBOOK:
  CLOCK: [2018-02-01 Thu 23:59]--[2018-02-02 Fri 01:10] =>  1:11
  CLOCK: [2018-01-30 Tue 19:12]--[2018-01-30 Tue 23:12] =>  4:00
  CLOCK: [2018-01-18 Thu 22:12]--[2018-01-18 Thu 23:12] =>  1:00
  :END:
** final project inspiration
*** matteo

    [[https://matteofgmoschella.github.io/theageofthecyclists/#myPage]]

*** james

    [[https://jsomper.github.io/prisondata/]]

** final project don'ts
*** james

    [[https://jsomper.github.io/Antisemitism-project/]]

    it, er... didn't work. like, at all.

    lesson: submit something that works!

*** ayushman

    [[https://ayushman07.github.io/Final-Project/]]

    that's a photo essay without any interactive component to it.

    lesson: there is "data" in the module name. read the spec and make sure you tick the boxes.

** week 5 presentations
*** Reminder

    #+BEGIN_QUOTE 
    Pick one journalism piece/tool that illustrates a format or technique. Produce a presentation and report on the piece, how it's built, and the landscape of that format/technique in online journalism today.
    #+END_QUOTE

*** Example topics

    Some examples (please don't use these - come up with one of your own!):

    [[https://www.nytimes.com/interactive/2017/01/15/us/politics/you-draw-obama-legacy.html]]
    Storytelling interactivity

    [[https://www.buzzfeed.com/heidiblake/the-tennis-racket]]
    Algorithmic journalism, computer-assisted journalism

    [[https://www.theguardian.com/world/interactive/2013/nov/01/snowden-nsa-files-surveillance-revelations-decoded]]
    All-rounder

*** More example topics

    [[https://panamapapers.icij.org/]]
    [[http://panamapapers.sueddeutsche.de/articles/56febff0a1bb8d3c3495adf4/]]
    Relational database, network analysis, follow-the-money approach

    [[http://drones.pitchinteractive.com/]]
    Data-led storytelling

    [[http://www.jplusplus.org/en/project/rentswatch/]]
    Crowdfunding + scraping

    [[http://newsroom.tools/]]
    [[http://otranscribe.com/]]
    Journalism Tools

** Running your Pythons

*** solution one: the old way

   A Python script is a file, eg *example.py*

   You run this file through the **command line** with 

   #+BEGIN_SRC
   > `python example.py`
   #+END_SRC

*** wait what?
    :PROPERTIES:
    :reveal_background: https://media.giphy.com/media/z8yYEX4pE3lkc/giphy.gif
    :reveal_background_trans: slide
    :END:
*** solution two: the notebook

    Python also comes with a set of utilities bundled in a GUI: [[http://nbviewer.jupyter.org/github/jupyter/notebook/blob/master/docs/source/examples/Notebook/Notebook%20Basics.ipynb][the Jupyter Notebook]]

    We can run Python notebooks from the university computers.

    [[./images/jupyter.png]]

** To write code, you use a text editor

   [[https://www.sublimetext.com][for example, Sublime Text]]

   #+BEGIN_QUOTE
   Why not Word, Mac's TextEdit?
   #+END_QUOTE

   These softwares are word processors. They add _lots_ of code around the words you actually see on screen.

** Let's see some syntax
*** Variables
**** Strings

   #+BEGIN_SRC python
    variable = 'some text'

    print variable
    > some text
   #+END_SRC

**** Integers

   #+BEGIN_SRC python
    variable = 1

    print variable
    > 1
   #+END_SRC

*** Variables (2): Lists

   #+BEGIN_SRC python
    list= [1, 2, 'basile']

    print(list)
    > [1,2,'basile']

    print(list[0])
    > 1

    print(list[1])
    > 2
   #+END_SRC

*** Variables (3): Objects/dictionaries

   #+BEGIN_SRC python
    addresses = {'Mum': '07439487463', 'Donal Trump': '573-555-5555'}

    print(addresses['Mum'])
    > 07439487463
   #+END_SRC

*** Conditional execution: `if/else`

   #+BEGIN_SRC python
    name = 'basile'
    if name is 'basile'
       print('okay!')

    > okay!
   #+END_SRC

*** Conditional execution: `if/else` (2)

   #+BEGIN_SRC python
    number = 10
    if number > 5:
        print('Wow, that's a big number!')
   #+END_SRC

*** Booleans
    In Python, they are `True` and `False`

   #+BEGIN_SRC python
    1 == 1
    "test" != "testing"
    "test" == 1
   #+END_SRC

*** Control flow: `for` loop

   #+BEGIN_SRC python
    list_of_letters = ['a', 'b', 'c']

    for letter in list_of_letters:
        print(letter)
   #+END_SRC

*** Methods and functions

   #+BEGIN_SRC python
    def add_two(x):
        return x + 2

    var = 1
    print(var)
    > 1

    add_two(var)
    > 3

    add_two('basile')
    > ERROR
   #+END_SRC

** web scraping free text in python
    [[./images/guido.png]]

*** output

    This is a comma-separated values format, where every line in the file is a data record.

    [[https://en.wikipedia.org/wiki/Comma-separated_values]]

    #+BEGIN_SRC 
    MP,Party,Constituency
    Heidi Alexander ,Labour,Lewisham East
    Rushanara Ali ,Labour,Bethnal Green and Bow
    Mr Graham Allen ,Labour,Nottingham North
    Lyn Brown ,Labour,West Ham
    Chris Bryant ,Labour,Rhondda
    Ms Karen Buck ,Labour,Westminster North
    Dawn Butler ,Labour,Brent Central
    #+END_SRC

*** How?

    - Open the page
    - Fire up your DevTools
    - Tinker with the DOM to spot the consistency
    - Understand the tree structure to reach the elements you want

    Scraping is all about targeting the right element(s), and/or identifying the patterns in the document.
    
    Because through programming, patterns can be pried open and stripped bare, leaving only the relevant information.

*** Let's get scraping

    [[https://order-order.com/2017/02/08/named-122-mps-voted-brexit/]]
* 3.1: Simple scraping in Python
  :LOGBOOK:
  CLOCK: [2018-02-05 Mon 22:59]--[2018-02-06 Tue 00:50] =>  1:51
  CLOCK: [2018-02-04 Sun 22:10]--[2018-02-04 Sun 22:23] =>  0:13
  CLOCK: [2018-02-04 Sun 20:38]--[2018-02-04 Sun 22:00] =>  1:22
  :END:

** recap from last week
*** Python syntax

    #+BEGIN_SRC python
    # a variable
    foo = 'bar'

    # a list
    aList = [1,2,'lol']

    # an if statement
    if 'lol' in aList:
        print('element found')

    # a for loop
    for element in foo:
        if 'lol' is element:
            print element
            # > 'lol'
    #+END_SRC

*** web scraping with BeautifulSoup

    #+BEGIN_SRC python
    url = 'https://order-order.com/2017/02/08/named-122-mps-voted-brexit/'
    response = requests.get(url)

    # parses HTML
    html = response.content

    # magic method
    soup = BeautifulSoup(html, 'lxml')

    # now we can work
    soup.findAll('html elements')
    #+END_SRC

** scraping traitors
*** understanding the page structure
    
    - two <blockquote>
    - each contaning many <em>
    - each <em> containing our data points
 
*** mostly, it looks like so

    "name (party - constituency)"

    eg 

    #+BEGIN_SRC 
    Martyn Day (Scottish National Party – Linlithgow and East Falkirk)
    Maria Eagle (Labour – Garston and Halewood)
    #+END_SRC

*** problems

    - a few _Labour (Co-op)
    - one SNP- Inverness

    This is the key issue with web scraping: dirty data!

*** back to our notebook!
** scraping: recap

   - for each <em> in each <blockquote>
   - split the text in different ways to create our variables
   - add our variables to a list
   - add this list to another list (a list of list, then)
   - each list in our list of list is a row
   - write CSV file

** scraping: result!

   [[./img/results.png]]

** spotting traitors

   Now that we've got our 122 names we want to see who betrayed their constituency: jump to `spotting-traitors`

*** links we used
    
   - [[https://www.shanelynn.ie/merge-join-dataframes-python-pandas-index-1/#mergetypes][merge types]]
   - [[https://jeffdelaney.me/blog/useful-snippets-in-pandas/][useful pandas snippets]]

*** reading

    - [[https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python][more pandas, a course]]
  
* 3.2: More complex scraping in Python?
  :LOGBOOK:
  CLOCK: [2018-02-08 Thu 21:37]--[2018-02-08 Thu 21:41] =>  0:04
  CLOCK: [2018-02-08 Thu 20:18]--[2018-02-08 Thu 21:03] =>  0:45
  CLOCK: [2018-02-08 Thu 18:27]--[2018-02-08 Thu 19:08] =>  0:41
  CLOCK: [2018-02-06 Tue 22:04]--[2018-02-06 Tue 22:20] =>  0:16
  CLOCK: [2018-02-06 Tue 20:53]--[2018-02-06 Tue 21:22] =>  0:29
  CLOCK: [2018-02-06 Tue 18:34]--[2018-02-06 Tue 19:17] =>  0:43
  CLOCK: [2018-02-04 Sun 22:00]--[2018-02-04 Sun 22:10] =>  0:10
  :END:
  
** javascript exercise

   #+BEGIN_QUOTE
   Build an interactive thing in Javascript, that responds to a user input.
   #+END_QUOTE

** assessment update
   #+ATTR_REVEAL: :frag (appear)
   - still waiting on deadlines to be updated
   - are you clear on what the week 5 assessment is?
   - final project: two routes...

** two routes for the final project
   #+ATTR_REVEAL: :frag (appear)

   - option one: build a full website
   - option two: host your content on Medium/blog/Wordpress

   Obviously I will assess the two options differently, i.e.

   #+ATTR_REVEAL: :frag (appear)
   - if you do more website, front-end work, I will be kinder on the data work
   - if you do little website-building, your data work must be top notch!

** scraping, scraping!

*** web scraping v API

    [[https://www.grepsr.com/web-scraping-vs-api/][a simple comparison]]:

   #+ATTR_REVEAL: :frag (appear)
    - is an API available/hidden?
    - is the API actually up-to-date?
    - rate limiting
    - but better structure
   
   One thing to consider: the ethics of web scraping: see this recent [[https://www.eff.org/deeplinks/2018/01/ninth-circuit-doubles-down-violating-websites-terms-service-not-crime][Ninth Circuit ruling]] that violating a website's term of service is not a crime

*** web scraping

    [[https://blog.hartleybrody.com/web-scraping/][Every website can be scraped]]*

   #+ATTR_REVEAL: :frag (appear)
   * if you're good enough
   
   good practice: set headers in your web requests identifying yourself

   #+BEGIN_SRC python
   import requests
 
   headers = {'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5);
                Basile Simon/ London/ basile.simon@thetimes.co.uk'}
   html = requests.get(url, headers=headers)
   #+END_SRC

   [[https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe][A good tutorial]]

*** API scraping

    using an API is using an authorised service

** tools of the trade: the APIs

   [[https://www.theguardian.com/media/pda/2007/dec/14/thenutshellabeginnersguide][even the Guardian has a piece about "what's an API"]]

   #+BEGIN_QUOTE
   The exception are sites built on open source code, which is sort of like a *worldwide hippy commune* of developers who share their notes. The idea is that they can make better products and software if lots of people collaborate on a project.
   #+END_QUOTE

   good API example: [[https://postcodes.io/][postcodes.io]]

** setup
*** register on twitter

    - log into your twitter account
    - register your phone number with your account
    - click on your profile pic (top left-hand side), then head to "Mobile"

*** create your (first?) twitter app

    https://apps.twitter.com/

    that's a common way to keep control of who's allowed to use your service.
    this way, they can shut your app down [[https://www.theverge.com/2015/6/4/8731387/politwoops-sunlight-foundation-twitter][if you abuse your privileges]]

    [[./img/twitter-app-create.png]]
    
*** fill in application details

    [[./img/twitter-app-info.png]]

*** DO NOT publish your API keys etc.

    some people scrape the internet for published credentials. they could take over your account, post whatever they want in your name, including sending DMs. you've been warned.
** how to use an API?

   - read the documentation
   - find a convenient wrapper library that does the heavy lifting for you

   in our case: that's [[http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html][tweepy]], a wrapper library around the twitter API built in python.

*** installing tweepy

    #+BEGIN_SRC 
    pip3 install tweepy
    #+END_SRC

*** more modules

    #+BEGIN_SRC 
    pip3 install pandas numpy matplotlib seaborn
    #+END_SRC


    [[http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html][Getting started with tweepy]]

** notes from the session

   - [[https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe][what's a dataframe?]]
   - [[https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python][mostly everything about pandas dataframes]]
   - [[https://stackoverflow.com/questions/26047209/what-is-the-difference-between-a-pandas-series-and-a-single-column-dataframe][a Series is one column of a dataframe]]
   - [[https://medium.freecodecamp.org/series-and-dataframe-in-python-a800b098f68][series and dataframes, cont.]]
* 4.1: R in the newsroom: the tidyverse
  :LOGBOOK:
  CLOCK: [2018-02-10 Sat 15:08]--[2018-02-10 Sat 22:49] =>  7:41
  :END:

** what is R

   R is a programming language very popular among statisticians, researchers, and data scientists.

   In addition to traditional data structures, R comes out of the box with regression models, time-series support, geo capabilities, and many stats shorthands.

   [[./images/R_logo.svg.png]]

** why R?

   FiveThirtyEight, Buzzfeed, The Times, The Guardian, some German newsrooms...

   for some reason R has gained popularity in newsrooms among data specialists

*** should I choose R or Python?

    no right answer to this question!
    R v Python: [[https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis][an infographic]]

   #+ATTR_REVEAL: :frag (appear)
   - many ways to write R: several schools of thought
   - Python is more consistent across users: meaningful indentation helps
   - you can do anything with Python, R is slightly more focused
   - Python online documentation/community is more beginner-friendly
   - pure salary from survey: R about +20% (one of the most top-paying languages)
   
    R isn't exactly the [[https://en.wikipedia.org/wiki/Zen_of_Python][Zen of Python...]]
    
** elements of syntax

*** the basics
    #+BEGIN_SRC R
    # a comment
    
    # a variable
    foo <- 'bar'
    
    # a list, called a 'vector'
    foo <- c(1, 2, 'lol')
    #+END_SRC

*** functions and for loops?

    the so-called "R way" is very much line-by-line, not that much oriented towards functions and iterators

    #+BEGIN_SRC R
    foo <- c(1, 3, 'some data', 'not to remove')
    foo_clean <- foo[-(1:2)]
    #+END_SRC


** the tidyverse

   there are several ways to write R. an important one follows Hadley Wickham's philosophy and work at RStudio.

   it is called *[[https://www.tidyverse.org/packages/][the tidyverse]*

   > The tidyverse is a coherent system of packages for data manipulation, exploration and visualization that share a common design philosophy

   [[./images/tidyverse1.png]]

*** tidy data

    [[https://hackyhour.github.io/Goettingen/slides/tidy_slides.html#/][principles of tidy data]], a presentation (built in RStudio!) from Wickham's paper [[http://vita.had.co.nz/papers/tidy-data.pdf]["Tidy Data"]]

*** a set of tools

    example: the pipe `%>%`

    #+BEGIN_SRC javascript
    const foo = [1,2,10];
    foo.forEach(function(element) {
      if (element > 2) {
        return element;
      }
    });
    #+END_SRC

    #+BEGIN_SRC R
    foo <- c(1,2,10)
    foo %>%
      filter( > 2)
    #+END_SRC

*** the pipe II

    > The operators pipe their left-hand side values forward into expressions that appear on the right-hand side, i.e. one can replace f(x) with x %>% f(), where %>% is the (main) pipe-operator. 

    #+BEGIN_SRC R
    the_data <-
      read.csv('/path/to/data/file.csv') %>%
      subset(variable_a > x) %>%
      transform(variable_c = variable_a/variable_b) %>%
      head(100)
    #+END_SRC


*** pipes and verbs

    #+BEGIN_SRC R
    cars <- cars %>%
      mutate(pounds = weight / 1000)
    #+END_SRC

** dplyr tutorial?

   [[http://genomicsclass.github.io/book/pages/dplyr_tutorial.html]]

** reading

   [[https://rpubs.com/aelhabr/tidyverse-basics][the super helpful cheatsheets]]

  https://tidyverse-intro.github.io/index.html
  https://pandas.pydata.org/pandas-docs/stable/comparison_with_r.html
  http://r4ds.had.co.nz/exploratory-data-analysis.html
  https://www.datacamp.com/courses/introduction-to-the-tidyverse
  http://www.business-science.io/timeseries-analysis/2017/07/23/tidy-timeseries-analysis-pt-2.html

* 4.2: R in the newsroom: ggplot
* 5.1: Data cleaning in R
* 5.2: Some stats in R
