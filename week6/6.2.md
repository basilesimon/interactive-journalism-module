# 6.2: ???


## recap from Wednesday


## exercise

based on the work we've done on Wednesday we're going to work through other examples


### example one

there is a file called  \`data/nama<sub>10r</sub><sub>3gdp</sub><sub>1</sub><sub>Data.csv</sub>\` that contains 2013 Power Purchasing Standard data

[what is the PPS?](http://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Purchasing_power_standard_(PPS)), you ask?

> The purchasing power standard is an artificial currency unit. Theoretically, one PPS can buy the same amount of goods and services in each country. However, price differences across borders mean that different amounts of national currency units are needed for the same goods and services depending on the country. PPS are derived by dividing any economic aggregate of a country in national currency by its respective purchasing power parities. 


### example one

1.  take this file, load it into R
2.  clean it if need be
3.  merge it with out results
4.  draw a scatterplot comparing PPS in each district with each party's vote share

remember: the file is called  \`data/nama<sub>10r</sub><sub>3gdp</sub><sub>1</sub><sub>Data.csv</sub>\` 


### example two

same deal, but with the number of patents per 10,000 inhabitants

the file is \`data/pat<sub>ep</sub><sub>rtec</sub><sub>1</sub><sub>Data.csv</sub>\`


## a look at linear regressions

> The linear regression is a linear approach for **modelling the relationship** between a scalar **dependent variable y** and one or more **explanatory variables** (or independent variables) denoted X.

ie how accurately does a variable help explain an observation?

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/220px-Linear_regression.svg.png)


### linear models in R

to fit a linear model onto a dataframe, we store the result of \`lm(x ~ y)\` into a variable:

    model <- lm(observation_column ~ variable_column,
                data=df)

in \`ggplot\`, \`geom<sub>smooth</sub>(method="lm")\` will draw a line onto our plot:

    ggplot(df, aes(x=x, y=y)) +
      geom_smooth(method="lm")


### but how good is my model?

R-squared is the metric you don't want to miss.

    > summary(model)
    Adjusted R-squared: somewhere between 0 and 1

the closer to 1 the better!


### correlation != causation

<https://www.ft.com/content/94e3acec-a767-11e7-ab55-27219df83c97>

r-squared indicates the strength of the relationship&#x2026; you can't infer causation from this.


### the outlier question

<https://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/>

